# Derived from ./manifests
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
data:
  elasticsearch.yml: |
    cluster.name: full-stack-cluster
    node.name: node-1
    path.data: /usr/share/elasticsearch/data
    http:
      host: 0.0.0.0
      port: 9200
    bootstrap.memory_lock: true
    transport.host: 127.0.0.1
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      initContainers:
      - name: set-vm-max-map-count
        image: busybox
        imagePullPolicy: IfNotPresent
        command: ['sysctl', '-w', 'vm.max_map_count=262144']
        securityContext:
          privileged: true
      - name: volume-mount-hack
        image: busybox
        imagePullPolicy: IfNotPresent
        command: ["sh", "-c", "chown -R 1000:100 /usr/share/elasticsearch/data"]
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:6.0.0-rc1
        imagePullPolicy: IfNotPresent
        env:
        - name: ES_JAVA_OPTS
          value: -Xms1024m -Xmx1024m
          # ES_MEM_LIMIT=2g
          # ES_JVM_HEAP=1024m
        ports:
        - containerPort: 9200
        resources:
          limits:
            memory: "2147483648"
        volumeMounts:
        - name: config
          mountPath: /usr/share/elasticsearch/elasticsearch.yml
          subPath: elasticsearch.yml
        - name: data
          mountPath: /usr/share/elasticsearch/data
      # Allow non-root user to access PersistentVolume
      securityContext:
        fsGroup: 1000
      restartPolicy: Always
      volumes:
      - name: config
        configMap:
          name: elasticsearch
      # - name: data
      #   persistentVolumeClaim:
      #     claimName: elasticsearch
      - name: data
        hostPath:
          path: /srv/elasticsearch-data
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
spec:
  # storageClassName: standard
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Mi
---
apiVersion: extensions/v1beta1
kind: PodSecurityPolicy
metadata:
  name: elasticsearch
spec:
  fsGroup:
    rule: RunAsAny
  privileged: true
  runAsUser:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  allowedCapabilities:
  - 'IPC_LOCK'
  - 'SYS_RESOURCE'
  supplementalGroups:
    rule: RunAsAny
  volumes:
  - '*'
  hostPID: true
  hostIPC: true
  hostNetwork: true
  hostPorts:
  - min: 1
    max: 65536
---
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: elasticsearch
rules:
- apiGroups:
  - extensions
  resources:
  - podsecuritypolicies
  resourceNames:
  - elasticsearch
  verbs:
  - use
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: elasticsearch
subjects:
- kind: ServiceAccount
  name: elasticsearch
  namespace: default
roleRef:
  kind: ClusterRole
  name: elasticsearch
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
---
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
spec:
  type: NodePort
  ports:
  - name: "api"
    port: 9200
    targetPort: 9200
  selector:
    app: elasticsearch
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-init-pipelines
  namespace: kube-system
  labels:
    app: filebeat
data:
  docker-logs.json: |
    {
      "description": "Pipeline for processing docker logs",
      "processors": [
        {
          "date": {
            "field": "time",
            "target_field": "@timestamp",
            "formats": [
              "yyyy-MM-dd'T'hh:mm:ss.SSSSSSSSSZ"
            ],
            "ignore_failure" : true
          }
        },
        {
          "remove": {
            "field": "time"
          }
        },
        {
          "set": {
            "field": "docker.message",
            "value": "{{_source.log}}"
          }
        },
        {
          "set": {
            "field": "type",
            "value": "docker"
          }
        },
        {
          "remove": {
            "field": "log"
          }
        },
        {
          "grok": {
            "field": "source",
            "patterns": [
              "%{GREEDYDATA}/%{DATA:docker.full_container_id}-json.log"
            ],
            "ignore_failure" : true
          }
        },
        {
          "script": {
            "lang": "painless",
            "inline": "ctx.docker.container_id = ctx.docker.full_container_id.substring(0,12);",
            "ignore_failure" : true
          }
        },
        {
          "grok": {
            "field": "docker.message",
            "patterns": ["%{DATA}%{LEVEL:docker.level}%{DATA}"],
            "pattern_definitions": {
              "LEVEL": "INFO|WARNING|ERROR|FATAL|DEBUG|TRACE"
            },
            "ignore_failure" : true
          }
        },
        {
          "date_index_name": {
            "field": "@timestamp",
            "index_name_prefix": "docker-logs-",
            "date_rounding": "M"
          }
        }
      ]
    }
---
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: filebeat-init-templates
#   labels:
#     app: filebeat
# data:
#   docker-logs.json: |
#     {
#       "template": "docker-logs-*",
#       "settings": {
#         "index": {
#           "number_of_shards": "1",
#           "mapper": {
#             "dynamic": "true"
#           }
#         }
#       },
#       "mappings": {
#         "_default_": {
#           "_all": {
#             "enabled": false
#           },
#           "properties": {
#               "@timestamp": {
#                 "type": "date"
#               },
#               "docker": {
#                 "properties": {
#                   "container_id": {
#                     "type": "keyword"
#                   },
#                   "full_container_id": {
#                     "type": "keyword"
#                   },
#                   "level": {
#                     "type": "keyword"
#                   },
#                   "message": {
#                     "type": "text"
#                   }
#                 }
#               },
#               "source": {
#                 "type": "keyword"
#               },
#               "stream": {
#                 "type": "keyword"
#               },
#               "hostname": {
#                 "type": "keyword"
#               },
#               "name": {
#                 "type": "keyword"
#               },
#               "version":{
#                 "type": "keyword"
#               },
#               "type":{
#                 "type": "keyword"
#               },
#               "input_type":{
#                 "type": "keyword"
#               }
#             }
#         }
#       }
#     }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-prospectors
  namespace: kube-system
  labels:
    app: filebeat
data:
  docker.yml: |
    # - type: log
    #   paths:
    #     - /hostfs/var/lib/docker/containers/*/*.log
    #   json.keys_under_root: true
    #   json.overwrite_keys: true
    #   close_inactive: 24h
    #   close_renamed: true
    #   pipeline: docker-logs
    #   processors:
    #     - add_kubernetes_metadata:
    #         in_cluster: true

  filebeat.yml: |
    - type: log
      paths:
        # - /hostfs/var/log/containers/*/*.log
        - /hostfs/var/lib/docker/containers/*/*.log
      json.keys_under_root: false
      json.overwrite_keys: false
      close_inactive: 24h
      close_renamed: true
      processors:
        - add_kubernetes_metadata:
            in_cluster: true
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat
  namespace: kube-system
  labels:
    app: filebeat
data:
  filebeat.yml: |
    filebeat.config:
      prospectors:
        path: ${path.config}/prospectors.d/*.yml
        reload.enabled: false
      modules:
        path: ${path.config}/modules.d/*.yml
        reload.enabled: false

    setup:
      dashboards.enabled: true
      kibana:
        host: "kibana.default.svc:5601"
        username: elastic
        password: changeme

    processors:
    - add_cloud_metadata:
    - add_kubernetes_metadata:
        in_cluster: true

    output.elasticsearch:
      hosts: ['elasticsearch.default.svc:9200']
      username: elastic
      password: changeme

    # filebeat.registry_file: /usr/share/filebeat/data/registry
    #
    # filebeat.config.prospectors:
    # #prospectors dynamically loaded from the sub-directory
    #   path: ${path.config}/prospectors.d/*.yml
    #   reload.enabled: false
    #
    # filebeat.modules:
    # #Filebeat system module consumes logs from host OS through a mounted volume
    # - module: system
    #   syslog:
    #     var.paths: ["/var/log/host/system.log*"]
    # #Nginx Module to consume to access and error logs from mounted volume
    # - module: nginx
    #   access:
    #     var.paths: ["/var/log/nginx/access.log*"]
    #   error:
    #     var.paths: ["/var/log/nginx/error.log*"]
    # #Apache2 Module to consume to access and error logs from mounted volume
    # - module: apache2
    #   access:
    #     var.paths: ["/var/log/apache2/access.log*"]
    #   error:
    #     var.paths: ["/var/log/apache2/error.log*"]
    # #Mysql module consumes error and mysql-slow logs from mounted volume
    # - module: mysql
    #   error:
    #     var.paths: ["/var/log/mysql/error.log*"]
    #   slowlog:
    #     var.paths: ["/var/log/mysql/mysql-slow.log*"]
    #
    # #All data to indexed to Elasticsearch
    # output.elasticsearch:
    #   hosts: ["elasticsearch:9200"]
---
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: filebeat
  namespace: kube-system
  labels:
    app: filebeat
spec:
  template:
    metadata:
      name: filebeat
      namespace: kube-system
      labels:
        app: filebeat
    spec:
      initContainers:
      - name: filebeat-init
        image: docker.elastic.co/beats/filebeat:6.0.0-rc1
        imagePullPolicy: IfNotPresent
        env:
        - name: ES_PASSWORD
          value: changeme
        command:
          - "sh"
          - "-c"
          - |
            chown -R 1000:100 /usr/share/filebeat/data
            # chown -R 1000:100 /hostfs/var/lib/docker/containers

            # until curl -u elastic:changeme -s http://elasticsearch:9200/_cat/health -o /dev/null; do
            #     echo Waiting for Elasticsearch...
            #     sleep 1
            # done
            # until curl -s http://kibana:5601/login -o /dev/null; do
            #     echo Waiting for Kibana...
            #     sleep 1
            # done
            #
            # # Load any declared ingest pipelines
            # PIPELINES=/usr/share/filebeat/pipelines.d/*.json
            # for f in $PIPELINES
            # do
            #   filename=$(basename $f)
            #   pipeline_id="${filename%.*}"
            #   echo "Loading $pipeline_id ingest chain..."
            #   curl -s  -H 'Content-Type: application/json' \
            #     -XPUT http://elastic:${ES_PASSWORD}@elasticsearch:9200/_ingest/pipeline/$pipeline_id -d@$f
            # done

            # # Load any declared extra index templates
            # TEMPLATES=/usr/share/filebeat/templates/*.json
            # for f in $TEMPLATES
            # do
            #   filename=$(basename $f)
            #   template_id="${filename%.*}"
            #   echo "Loading $template_id template..."
            #   curl -s  -H 'Content-Type: application/json' \
            #     -XPUT http://elastic:${ES_PASSWORD}@elasticsearch:9200/_template/$template_id -d@$f
            #   #We assume we want an index pattern in kibana
            #   curl -s -XPUT http://elastic:${ES_PASSWORD}@elasticsearch:9200/.kibana/index-pattern/$template_id-* \
            #     -d "{\"title\" : \"$template_id-*\",  \"timeFieldName\": \"@timestamp\"}"
            # done
        securityContext:
          runAsUser: 0
        volumeMounts:
        # - name: init-pipelines
        #   mountPath: /usr/share/filebeat/pipelines.d
        # - name: init-templates
        #   mountPath: /usr/share/filebeat/templates.d
        - name: data
          mountPath: /usr/share/filebeat/data
        # - name: hostfs-containers
        #   mountPath: /hostfs/var/lib/docker/containers
      containers:
      - name: filebeat
        image: docker.elastic.co/beats/filebeat:6.0.0-rc1
        imagePullPolicy: IfNotPresent
        args:
        - filebeat
        - -e
        - -E
        - output.elasticsearch.username=elastic
        - -E
        - output.elasticsearch.password=changeme
        - -strict.perms=false
        securityContext:
          runAsUser: 0
        resources: {}
        volumeMounts:
        - name: config
          mountPath: /usr/share/filebeat/filebeat.yml
          subPath: filebeat.yml
        - name: config-prospectors
          mountPath: /usr/share/filebeat/prospectors.d/
        - name: hostfs-log
          mountPath: /hostfs/var/log
        - name: hostfs-docker-containers
          mountPath: /hostfs/var/lib/docker/containers
        - name: data
          mountPath: /usr/share/filebeat/data/
        - name: minikube-var-lib-docker-containers
          mountPath: /mnt/sda1/var/lib/docker/containers

        # - mountPath: /var/log/nginx/
        # - mountPath: /var/log/apache2/
        # - mountPath: /var/log/mysql/
        # - mountPath: /var/log/host/
        #   readOnly: true

      securityContext:
        fsGroup: 1000
      volumes:
      # - name: init-pipelines
      #   configMap:
      #     name: filebeat-init-pipelines
      # - name: init-templates
      #   configMap:
      #     name: filebeat-init-templates
      - name: config
        configMap:
          name: filebeat
      - name: config-prospectors
        configMap:
          name: filebeat-prospectors
      # - name: data
      #   persistentVolumeClaim:
      #     claimName: filebeat
      - name: data
        hostPath:
          path: /srv/filebeat-data
      - name: hostfs-log
        hostPath:
          path: /var/log
      - name: hostfs-docker-containers
        hostPath:
          path: /var/lib/docker/containers
      - name: minikube-var-lib-docker-containers
        hostPath:
          path: /mnt/sda1/var/lib/docker/containers
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: filebeat
  namespace: kube-system
  labels:
    app: filebeat
spec:
  storageClassName: standard
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Mi
---
# apiVersion: v1
# kind: Namespace
# metadata:
#   name: logging-fluentd
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd
  # namespace: logging-fluentd
  labels:
    app: fluentd
data:
  # see also https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/fluentd-elasticsearch/fluentd-es-image/td-agent.conf
  # https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter
  # https://groups.google.com/forum/#!msg/fluentd/CMZf4cTPlow/GADnOFIsBQAJ
  # https://github.com/fabric8io/docker-fluentd-kubernetes/issues/11
  # > Yeah, I use this plugin to regroup multilines (with multiline_start_regexp parameter) from my JSON docker logs on kubernetes (with ES /Fluentd / Kibana associated ), an then I parse them with fluent-plugin-parser , so I can handle correctly traceback and other multilines logs in elasticsearch.
  #
  # fluent-plugin-concat, fluent-plugin-parser, rewrite_tag_filter
  # https://github.com/fluent/fluent-plugin-rewrite-tag-filter
  #
  # http://dev.haufe.io/fluentd-log-parsing/ !!
  #
  # fluent-plugin-grok-parser
  #
  # https://github.com/fluent/fluentd/blob/master/ChangeLog

  fluent.conf: |
    @include kubernetes.conf

    <match **>
      type elasticsearch
      log_level info
      include_tag_key true
      host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
      port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
      scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'http'}"
      # user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
      # password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
      reload_connections "#{ENV['FLUENT_ELASTICSEARCH_RELOAD_CONNECTIONS'] || 'true'}"
      logstash_prefix "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX'] || 'logstash'}"
      logstash_format true
      buffer_chunk_limit 2M
      buffer_queue_limit 32
      flush_interval 5s
      max_retry_wait 30
      disable_retry_limit
      num_threads 8
    </match>

  kubernetes.conf: |
    # https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter/blob/master/README.md

    <match fluent.**>
      type null
    </match>

    <source>
      type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      time_format %Y-%m-%dT%H:%M:%S.%NZ
      # tag_to_kubernetes_name_regexp \.(?<pod_name>[^\._]+)_(?<namespace>[^_]+)_(?<container_name>.+)-(?<docker_id>[a-z0-9]{64})\.log$</pod>)
      tag kubernetes.*
      format json
      read_from_head true
    </source>

    <source>
      type tail
      format /^(?<time>[^ ]* [^ ,]*)[^\[]*\[[^\]]*\]\[(?<severity>[^ \]]*) *\] (?<message>.*)$/
      time_format %Y-%m-%d %H:%M:%S
      path /var/log/salt/minion
      pos_file /var/log/fluentd-salt.pos
      tag salt
    </source>

    <source>
      type tail
      format syslog
      path /var/log/startupscript.log
      pos_file /var/log/fluentd-startupscript.log.pos
      tag startupscript
    </source>

    <source>
      type tail
      format /^time="(?<time>[^)]*)" level=(?<severity>[^ ]*) msg="(?<message>[^"]*)"( err="(?<error>[^"]*)")?( statusCode=($<status_code>\d+))?/
      path /var/log/docker.log
      pos_file /var/log/fluentd-docker.log.pos
      tag docker
    </source>

    <source>
      type tail
      format none
      path /var/log/etcd.log
      pos_file /var/log/fluentd-etcd.log.pos
      tag etcd
    </source>

    <source>
      type tail
      format kubernetes
      multiline_flush_interval 5s
      path /var/log/kubelet.log
      pos_file /var/log/fluentd-kubelet.log.pos
      tag kubelet
    </source>

    <source>
      type tail
      format kubernetes
      multiline_flush_interval 5s
      path /var/log/kube-proxy.log
      pos_file /var/log/fluentd-kube-proxy.log.pos
      tag kube-proxy
    </source>

    <source>
      type tail
      format kubernetes
      multiline_flush_interval 5s
      path /var/log/kube-apiserver.log
      pos_file /var/log/fluentd-kube-apiserver.log.pos
      tag kube-apiserver
    </source>

    <source>
      type tail
      format kubernetes
      multiline_flush_interval 5s
      path /var/log/kube-controller-manager.log
      pos_file /var/log/fluentd-kube-controller-manager.log.pos
      tag kube-controller-manager
    </source>

    <source>
      type tail
      format kubernetes
      multiline_flush_interval 5s
      path /var/log/kube-scheduler.log
      pos_file /var/log/fluentd-kube-scheduler.log.pos
      tag kube-scheduler
    </source>

    <source>
      type tail
      format kubernetes
      multiline_flush_interval 5s
      path /var/log/rescheduler.log
      pos_file /var/log/fluentd-rescheduler.log.pos
      tag rescheduler
    </source>

    <source>
      type tail
      format kubernetes
      multiline_flush_interval 5s
      path /var/log/glbc.log
      pos_file /var/log/fluentd-glbc.log.pos
      tag glbc
    </source>

    <source>
      type tail
      format kubernetes
      multiline_flush_interval 5s
      path /var/log/cluster-autoscaler.log
      pos_file /var/log/fluentd-cluster-autoscaler.log.pos
      tag cluster-autoscaler
    </source>

    <filter kubernetes.**>
      type kubernetes_metadata
    </filter>

    <filter kubernetes.var.log.containers.nginx-ingress-controller-**>
      # https://github.com/kubernetes/ingress/tree/master/controllers/nginx#log-format
      type parser
      reserve_data true
      hash_value_field parsed
      key_name log
      format /^(?<remote_addr>[^ ]*) - \[(?<proxy_add_x_forwarded_for>[^\]]*)\] - (?<remote_user>[^ ]*) \[(?<time_local>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*) +\S*)?" (?<status>[^ ]*) (?<body_bytes_sent>[^ ]*)(?: "(?<http_referer>[^\"]*)" "(?<http_user_agent>[^\"]*)")?.*$/
    </filter>

    # <filter kubernetes.var.log.containers.nginx-ingress-controller-**>
    #   type record_transformer
    #   <record>
    #     message "#{parsed.method} #{parsed.path} #{parsed.status}"
    #   </record>
    # </filter>

  # prometheus.conf: |
  #   # https://github.com/kazegusuri/fluent-plugin-prometheus#usage
  #
  #   <source>
  #     @type prometheus
  #   </source>
  #
  #   <source>
  #     @type prometheus_monitor
  #   </source>
  #
  #   <filter **>
  #     @type prometheus
  #     <metric>
  #       name fluentd_records_total
  #       type counter
  #       desc The total number of records read by fluentd.
  #     </metric>
  #   </filter>
---
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: fluentd
  labels:
    app: fluentd
spec:
  template:
    metadata:
      name: fluentd
      labels:
        app: fluentd
    spec:
      serviceAccountName: fluentd
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v0.12.33-elasticsearch
        imagePullPolicy: IfNotPresent
        env:
        - name:  FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.default.svc"
        - name:  FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name:  FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX
          value: "fluentd"
        - name: DEBUG
          value: "true"
        volumeMounts:
        - name: config
          mountPath: /fluentd/etc
        - name: host-var-log
          mountPath: /var/log
        - name: host-var-lib-docker-containers
          mountPath: /var/lib/docker/containers
          # readOnly: true
        - name: minikube-var-lib-docker-containers
          mountPath: /mnt/sda1/var/lib/docker/containers
        # securityContext:
        #   runAsUser: 0
      volumes:
      - name: config
        configMap:
          name: fluentd
      - name: host-var-log
        hostPath:
          path: /var/log
      - name: host-var-lib-docker-containers
        hostPath:
          path: /var/lib/docker/containers
      - name: minikube-var-lib-docker-containers
        hostPath:
          path: /mnt/sda1/var/lib/docker/containers
---
# see https://github.com/kubernetes/kubernetes/issues/44778
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  labels:
    app: fluentd
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: fluentd
  labels:
    app: fluentd
rules:
- apiGroups: [""] # core API group
  resources: ["pods", "namespaces"]
  verbs: ["get", "watch", "list"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: fluentd
  labels:
    app: fluentd
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: default
  # namespace: logging-fluentd
roleRef:
  kind: ClusterRole
  name: fluentd
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kibana
  labels:
    app: kibana
data:
  kibana.yml: |
    server:
      name: "full-stack-example"
      port: 127.0.0.1:5601
    elasticsearch.url: "http://elasticsearch:9200"
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: kibana
  labels:
    app: kibana
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: kibana
    spec:
      # FIXME
      # healthcheck + resources
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:6.0.0-rc1
        imagePullPolicy: IfNotPresent
        env:
        - name: ELASTICSEARCH_PASSWORD
          value: changeme
        ports:
        - containerPort: 5601
        resources: {}
        volumeMounts:
        - name: config
          mountPath: /usr/share/kibana/kibana.yml
          subPath: kibana.yml
      restartPolicy: Always
      volumes:
      - name: config
        configMap:
          name: kibana
---
apiVersion: v1
kind: Service
metadata:
  name: kibana
  labels:
    app: kibana
spec:
  type: NodePort
  ports:
  - name: "ui"
    port: 5601
    targetPort: 5601
  selector:
    app: kibana
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: metricbeat-modules
  labels:
    app: metricbeat
data:
  docker.yml: |
    - module: docker
      metricsets: ["container", "cpu", "diskio", "healthcheck", "info", "memory", "network"]
      hosts: ["unix:///var/run/docker.sock"]
      period: 10s

      # To connect to Docker over TLS you must specify a client and CA certificate.
      #ssl:
        #certificate_authority: "/etc/pki/root/ca.pem"
        #certificate:           "/etc/pki/client/cert.pem"
        #key:                   "/etc/pki/client/cert.key"

  kubernetes.yml: |
    # Node metrics, from kubelet:
    - module: kubernetes
      metricsets:
        - node
        - system
        - pod
        - container
        - volume
      period: 10s
      hosts: ["localhost:10255"]

    # State metrics from kube-state-metrics service:
    - module: kubernetes
      enabled: false
      metricsets:
        - state_node
        - state_deployment
        - state_replicaset
        - state_pod
        - state_container
      period: 10s
      hosts: ["kube-state-metrics:8080"]

    # Kubernetes events
    - module: kubernetes
      enabled: false
      metricsets:
        - event

  system.yml: |
    - module: system
      period: 10s
      metricsets:
        - cpu
        - load
        - memory
        - network
        - process
        - process_summary
        #- core
        #- diskio
        #- socket
      processes: ['.*']
      process.include_top_n:
        by_cpu: 5      # include top 5 processes by CPU
        by_memory: 5   # include top 5 processes by memory
      # cpu_ticks: true
      # process.cgroups.enabled: true

    - module: system
      period: 1m
      metricsets:
        - filesystem
        - fsstat
      processors:
      - drop_event.when.regexp:
          system.filesystem.mount_point: '^/(sys|cgroup|proc|dev|etc|host|lib)($|/)'
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: metricbeat
  labels:
    app: metricbeat
data:
  metricbeat.yml: |
    metricbeat.config.modules:
      path: ${path.config}/modules.d/*.yml
      reload.enabled: false

    setup:
      dashboards.enabled: true
      kibana:
        host: "kibana:5601"
        username: elastic
        password: changeme

    processors:
    - add_cloud_metadata:

    output.elasticsearch:
      hosts: ['elasticsearch:9200']
      username: elastic
      password: changeme

    # metricbeat.config.modules:
    # #Modules are enabled by reading the .modules.d sub directory. Changes to these will automatically be detected and reflected.
    #   path: ${path.config}/modules.d/*.yml
    #   reload.period: 10s
    #   reload.enabled: true
    # #All data indexed to Elasticsearch
    # output.elasticsearch:
    #   hosts: ["elasticsearch:9200"]
    # logging.to_files: false
---
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: metricbeat
  labels:
    app: metricbeat
spec:
  template:
    metadata:
      name: metricbeat
      labels:
        app: metricbeat
    spec:
      containers:
      - name: metricbeat
        image: docker.elastic.co/beats/metricbeat:6.0.0-rc1
        imagePullPolicy: IfNotPresent
        args:
        - metricbeat
        - -e
        - -system.hostfs=/hostfs
        - -E
        - output.elasticsearch.username=elastic
        - -E
        - output.elasticsearch.password=changeme
        - -strict.perms=false
        resources: {}
        securityContext:
          runAsUser: 0
        volumeMounts:
        - name: config
          mountPath: /usr/share/metricbeat/metricbeat.yml
          subPath: metricbeat.yml
        - name: config-modules
          mountPath: /usr/share/metricbeat/modules.d/
        # - name: hostfs-proc
        #   mountPath: /hostfs/proc
        #   readOnly: true
        # - name: hostfs-cgroup
        #   mountPath: /hostfs/sys/fs/cgroup
        #   readOnly: true
        - name: hostfs
          mountPath: /hostfs
          readOnly: true
        - name: hostfs-docker-sock
          mountPath: /var/run/docker.sock
          subPath: docker.sock
      # hostNetwork: true
      securityContext:
        fsGroup: 1000
      volumes:
      - name: config
        configMap:
          name: metricbeat
      - name: config-modules
        configMap:
          name: metricbeat-modules
      # - name: hostfs-proc
      #   hostPath:
      #     path: /proc
      # - name: hostfs-cgroup
      #   hostPath:
      #     path: /sys/fs/cgroup
      - name: hostfs
        hostPath:
          path: /
      - name: hostfs-docker-sock
        hostPath:
          path: /var/run
